{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LAB4:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "q1)Demonstrate how to load a dataset suitable for recommendation systems into a PySpark\n",
    "DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext\n",
    "spark = SparkSession.builder.appName('MovieRecommendation').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file_path = \"movies.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_df = spark.read.json(json_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- helpfulness: string (nullable = true)\n",
      " |-- product_id: string (nullable = true)\n",
      " |-- profile_name: string (nullable = true)\n",
      " |-- review: string (nullable = true)\n",
      " |-- score: double (nullable = true)\n",
      " |-- summary: string (nullable = true)\n",
      " |-- time: long (nullable = true)\n",
      " |-- user_id: string (nullable = true)\n",
      "\n",
      "+-----------+----------+--------------------+--------------------+-----+--------------------+----------+--------------+\n",
      "|helpfulness|product_id|        profile_name|              review|score|             summary|      time|       user_id|\n",
      "+-----------+----------+--------------------+--------------------+-----+--------------------+----------+--------------+\n",
      "|        7/7|B003AI2VGA|Brian E. Erland \"...|Synopsis: On the ...|  3.0|\"There Is So Much...|1182729600|A141HP4LYPWMSR|\n",
      "|        4/4|B003AI2VGA|          Grady Harp|THE VIRGIN OF JUA...|  3.0|Worthwhile and Im...|1181952000|A328S9RN3U5M68|\n",
      "|       8/10|B003AI2VGA|Chrissy K. McVay ...|The scenes in thi...|  5.0|This movie needed...|1164844800|A1I7QGUDP043DG|\n",
      "|        1/1|B003AI2VGA|        golgotha.gov|THE VIRGIN OF JUA...|  3.0|distantly based o...|1197158400|A1M5405JH9THP9|\n",
      "|        1/1|B003AI2VGA|KerrLines \"&#34;M...|Informationally, ...|  3.0|\"What's going on ...|1188345600| ATXL536YX71TR|\n",
      "|        0/0|B003AI2VGA|abra \"a devoted r...|The murders in Ju...|  2.0|Pretty pointless ...|1229040000|A3QYDL5CDNYN66|\n",
      "|       3/11|B003AI2VGA| Charles R. Williams|Mexican men are m...|  1.0|This is junk, sta...|1164153600| AQJVNDW6YZFQS|\n",
      "|      64/65|B00006HAXW|   Anthony Accordino|Over the past few...|  5.0|A  Rock N Roll Hi...|1060473600| AD4CDZK7D31XP|\n",
      "|      26/26|B00006HAXW|    Joseph P. Aiello|I recvd this vide...|  5.0|A  MUST-HAVE  vid...|1041292800|A3Q4S5DFVPB70D|\n",
      "|      24/24|B00006HAXW|     \"bruce_from_la\"|Wow! When I saw t...|  5.0|If You Like DooWo...|1061164800|A2P7UB02HAVEPB|\n",
      "|      22/23|B00006HAXW|    Henrique Peirano|I have the Doo Wo...|  4.0|    I expected more.|1039564800|A2TX99AZKDK0V7|\n",
      "|      14/14|B00006HAXW|      Richard Albero|Having worked in ...|  5.0|Professional Exce...|1045526400| AFC8IKR407HSK|\n",
      "|        9/9|B00006HAXW|                 Les|The people who ha...|  5.0|Marvelous, just M...|1062979200|A1FRPGQYQTAOR1|\n",
      "|        9/9|B00006HAXW|     Joseph M. Kotow|I have all of the...|  5.0|Pittsburgh - Home...|1042502400|A1RSDE90N6RSZF|\n",
      "|        7/7|B00006HAXW|      \"fellafromnyc\"|The performance o...|  4.0|They sang in the ...|1049846400|A1OUBOGB5970AO|\n",
      "|        7/7|B00006HAXW|           S. Dorman|Get it, also get ...|  5.0|DOO WOP RECORDED ...|1047945600|A3NPHQVIY59Y0Y|\n",
      "|        7/7|B00006HAXW|                 RFP|Excellent, excell...|  5.0|ROCK RYTHM AND DO...|1038787200| AFKMBAY28XO8A|\n",
      "|        4/4|B00006HAXW|           C. Thomas|This video is awe...|  5.0|Unbelievable Best...|1177804800| A66KMXH9V7OGU|\n",
      "|        3/3|B00006HAXW|   Michael A. Martin|As I stated in my...|  5.0|Another outstandi...|1200096000| AFJ27ZV9183B8|\n",
      "|        5/6|B00006HAXW|C. W. Emblom \"Bil...|I own both the VH...|  5.0|Outstanding Wheth...|1082592000| AXMKAXC0TR9AW|\n",
      "+-----------+----------+--------------------+--------------------+-----+--------------------+----------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movie_df.printSchema()\n",
    "movie_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------+----------+\n",
      "|       user_id|product_id|prediction|\n",
      "+--------------+----------+----------+\n",
      "|A12G4VIVXEQCIU|B002OHDRF2|  2.086684|\n",
      "|A145CT70T2SB51|B0012EM5GK|   4.99829|\n",
      "| A13F2IV3ME23R|B0095D5454| 1.2136644|\n",
      "|A13TO1ZFAH9SVN|B0001G6PZC| 3.9212952|\n",
      "|A11L5M4MJP00UW|B00004CQT3| 4.3138766|\n",
      "|A104NCZUD52CWG|B000063W82|       NaN|\n",
      "|A1078L9AXZRGT7|B000063W82|       NaN|\n",
      "|A10LIHFA4SSK3F|0790747324|       NaN|\n",
      "|A10YFAFXHLG8E0|B006FYGF8Q|       NaN|\n",
      "|A11977Q3OXQYHD|B00096S43U|       NaN|\n",
      "|A11JC53JUZ0TBK|B000063W82|       NaN|\n",
      "|A11NH0A73VNNA6|6304286961|       NaN|\n",
      "|A11Q4DC4YPPZGF|6300147967|       NaN|\n",
      "|A12EBC36D9QZ9N|B000063W82|       NaN|\n",
      "|A12PNLQL3E6W4C|B000063W1R|       NaN|\n",
      "|A12RIAPL805Q1H|B0016OLXN2|       NaN|\n",
      "|A136PLHJQM66U8|B000063W82|       NaN|\n",
      "|A13RM1AWD1C5ZR|B0001G6PZC|-0.6594128|\n",
      "|A13IKSGDYNBNQS|B0001G6PZC| 0.2884937|\n",
      "|A10CJINP7KBR4W|B002OHDRF2| 2.8847647|\n",
      "+--------------+----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#q2\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# Create a Spark session\n",
    "spark = SparkSession.builder.appName(\"RecommendationModel\").getOrCreate()\n",
    "\n",
    "# Read data from a JSON file\n",
    "json_file_path = \"movies.json\"\n",
    "df = spark.read.json(json_file_path)\n",
    "\n",
    "# Extract relevant columns for recommendation\n",
    "df = df.select(\"user_id\", \"product_id\", \"score\")\n",
    "\n",
    "# Convert user_id and product_id to numeric indices\n",
    "user_indexer = StringIndexer(inputCol=\"user_id\", outputCol=\"user_index\", handleInvalid=\"keep\")\n",
    "product_indexer = StringIndexer(inputCol=\"product_id\", outputCol=\"product_index\", handleInvalid=\"keep\")\n",
    "\n",
    "# Create an ALS (Alternating Least Squares) recommendation model\n",
    "als = ALS(maxIter=5, regParam=0.01, userCol=\"user_index\", itemCol=\"product_index\", ratingCol=\"score\")\n",
    "\n",
    "# Create a pipeline to execute the indexers and ALS model\n",
    "pipeline = Pipeline(stages=[user_indexer, product_indexer, als])\n",
    "\n",
    "# Split the data into training and test sets\n",
    "(training_data, test_data) = df.randomSplit([0.8, 0.2])\n",
    "\n",
    "# Train the recommendation model\n",
    "model = pipeline.fit(training_data)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = model.transform(test_data)\n",
    "\n",
    "# Show the predictions\n",
    "predictions.select(\"user_id\", \"product_id\", \"prediction\").show()\n",
    "\n",
    "# Stop the Spark session\n",
    "spark.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lplab/anaconda3/lib/python3.7/site-packages/pyspark/context.py:317: FutureWarning: Python 3.7 support is deprecated in Spark 3.4.\n",
      "  warnings.warn(\"Python 3.7 support is deprecated in Spark 3.4.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------+----------+\n",
      "|       user_id|product_id|prediction|\n",
      "+--------------+----------+----------+\n",
      "|A103EXN5Q7HX6Z|B0095D5454|       NaN|\n",
      "|A10LIHFA4SSK3F|0790747324|       NaN|\n",
      "|A10UVC4IRS4C6E|B0001G6PZC|       NaN|\n",
      "|A112G91I1ZR2A7|B000063W82|       NaN|\n",
      "|A112H6LPW6II9W|B00022VM5I|       NaN|\n",
      "|A112UYCJEYZPIP|B000063W1R|       NaN|\n",
      "|A113ZY9KU8TONV|B000063W82|       NaN|\n",
      "|A11EUXRL9HXW6R|B0001G6PZC|       NaN|\n",
      "|A11NH0A73VNNA6|6304286961|       NaN|\n",
      "|A128X98AP594F9|B000UGBOT0|       NaN|\n",
      "|A12E0VBOOXB2C9|B0001G6PZC|       NaN|\n",
      "|A12FDY8QMUW9V5|B000UGBOT0|       NaN|\n",
      "|A13BLSXL78EMRX|0790747324|       NaN|\n",
      "|A13F8LV1XX4UHQ|B000063W1R|       NaN|\n",
      "|A13K020ZYYSQZW|B00096S43K|       NaN|\n",
      "|A13NO1WIGJZUV4|B0071AD95K|       NaN|\n",
      "|A13OMT8D4GPIBV|6304286961| 2.8824651|\n",
      "|A12Q0LLN5R2XAG|B002OHDRF2| 4.8133097|\n",
      "|A10ODC971MDHV8|B000063W1R|  3.477895|\n",
      "|A13IKSGDYNBNQS|B0001G6PZC|-0.5216845|\n",
      "+--------------+----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#q3\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# Create a Spark session\n",
    "spark = SparkSession.builder.appName(\"RecommendationModel\").getOrCreate()\n",
    "\n",
    "# Read data from a JSON file\n",
    "json_file_path = \"movies.json\"\n",
    "df = spark.read.json(json_file_path)\n",
    "\n",
    "# Extract relevant columns for recommendation\n",
    "df = df.select(\"user_id\", \"product_id\", \"score\")\n",
    "\n",
    "# Convert user_id and product_id to numeric indices\n",
    "user_indexer = StringIndexer(inputCol=\"user_id\", outputCol=\"user_index\", handleInvalid=\"keep\")\n",
    "product_indexer = StringIndexer(inputCol=\"product_id\", outputCol=\"product_index\", handleInvalid=\"keep\")\n",
    "\n",
    "# Create an ALS (Alternating Least Squares) recommendation model\n",
    "als = ALS(maxIter=5, regParam=0.01, userCol=\"user_index\", itemCol=\"product_index\", ratingCol=\"score\")\n",
    "\n",
    "# Create a pipeline to execute the indexers and ALS model\n",
    "pipeline = Pipeline(stages=[user_indexer, product_indexer, als])\n",
    "\n",
    "# Split the data into training and test sets\n",
    "(training_data, test_data) = df.randomSplit([0.8, 0.2])\n",
    "\n",
    "# Train the recommendation model\n",
    "model = pipeline.fit(training_data)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = model.transform(test_data)\n",
    "\n",
    "# Show the predictions\n",
    "predictions.select(\"user_id\", \"product_id\", \"prediction\").show()\n",
    "\n",
    "# Stop the Spark session\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lplab/anaconda3/lib/python3.7/site-packages/pyspark/context.py:317: FutureWarning: Python 3.7 support is deprecated in Spark 3.4.\n",
      "  warnings.warn(\"Python 3.7 support is deprecated in Spark 3.4.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE): 4.330354686520405\n"
     ]
    }
   ],
   "source": [
    "#q4\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# Create a Spark session\n",
    "spark = SparkSession.builder.appName(\"RecommendationModel\").getOrCreate()\n",
    "\n",
    "# Read data from a JSON file\n",
    "json_file_path = \"movies.json\"\n",
    "df = spark.read.json(json_file_path)\n",
    "\n",
    "# Extract relevant columns for recommendation\n",
    "df = df.select(\"user_id\", \"product_id\", \"score\")\n",
    "\n",
    "# Check for missing or NaN values in the 'score' column\n",
    "df = df.dropna(subset=[\"score\"])\n",
    "\n",
    "# Convert user_id and product_id to numeric indices\n",
    "user_indexer = StringIndexer(inputCol=\"user_id\", outputCol=\"user_index\", handleInvalid=\"keep\")\n",
    "product_indexer = StringIndexer(inputCol=\"product_id\", outputCol=\"product_index\", handleInvalid=\"keep\")\n",
    "\n",
    "# Create an ALS (Alternating Least Squares) recommendation model\n",
    "als = ALS(maxIter=5, regParam=0.01, userCol=\"user_index\", itemCol=\"product_index\", ratingCol=\"score\")\n",
    "\n",
    "# Create a pipeline to execute the indexers and ALS model\n",
    "pipeline = Pipeline(stages=[user_indexer, product_indexer, als])\n",
    "\n",
    "# Split the data into training and test sets\n",
    "(training_data, test_data) = df.randomSplit([0.8, 0.2])\n",
    "\n",
    "# Train the recommendation model\n",
    "model = pipeline.fit(training_data)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = model.transform(test_data)\n",
    "\n",
    "# Check for NaN values in the 'prediction' column\n",
    "predictions = predictions.dropna(subset=[\"prediction\"])\n",
    "\n",
    "# Evaluate the model using RMSE\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"score\", predictionCol=\"prediction\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "\n",
    "# Stop the Spark session\n",
    "spark.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
